# Automated Security Log Analytics Pipeline

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Polars](https://img.shields.io/badge/Polars-1.0+-purple.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

Pipeline ETL automatizado para transformar logs crudos de seguridad en inteligencia de negocio procesable.

---

## ‚ö° Desempe√±o: Polars vs Pandas

### Caso de Estudio Breve: Procesando 50,000 Registros de Log

| M√©trica | Pandas | Polars | Mejora |
|---------|--------|--------|--------|
| **Lectura CSV** | 145ms | 28ms | 5.2x m√°s r√°pido |
| **Conversi√≥n de Tipos** | 82ms | 12ms | 6.8x m√°s r√°pido |
| **Filtrado & Agregaci√≥n** | 156ms | 21ms | 7.4x m√°s r√°pido |
| **Tiempo Total Pipeline** | **383ms** | **61ms** | **6.3x m√°s r√°pido** |

**Insight Clave:** Al procesar 50,000 logs mensuales, Polars reduce la ejecuci√≥n del pipeline de 383ms a 61ms‚Äîuna **mejora de rendimiento de 6.3x**.

**¬øPor qu√© Polars?**
- **Operaciones Vectorizadas**: Escrito en Rust con optimizaciones zero-copy
- **Eficiente en Memoria**: Usa formato columnar Apache Arrow vs almacenamiento basado en filas de NumPy
- **Mejor Escalabilidad**: Supera a Pandas exponencialmente a medida que crece el tama√±o del conjunto de datos

**Ejecuta Tu Propio Benchmark:**
```bash
python benchmarks/compare_polars_pandas.py
```

Esto genera una comparaci√≥n de desempe√±o detallada en el conjunto de datos mock real.

---

## Contexto de Negocio y Problema

**El Cliente:** Una empresa de gesti√≥n inmobiliaria manejando datos sensibles de propiedades.

**La Infraestructura:** Una aplicaci√≥n web Next.js protegida por un Edge Middleware personalizado que registra cada petici√≥n en una base de datos Supabase (PostgreSQL).

**El Problema:** El sistema generaba ~50,000 entradas de log por mes. El equipo de IT ten√≠a **cero visibilidad** sobre estos datos. No pod√≠an responder preguntas b√°sicas como:
- *"¬øEstamos bajo ataque ahora mismo?"*
- *"¬øEl geo-blocking realmente funciona?"*
- *"¬øCu√°nto de nuestro tr√°fico son bots vs clientes reales?"*

**Mi Rol:** Fui contratado para dise√±ar e implementar un **Pipeline de Datos Automatizado** que extrajera estos datos crudos, los transformara en m√©tricas significativas y entregara un reporte mensual de inteligencia de seguridad a los stakeholders.

---

## Arquitectura T√©cnica

Dise√±√© una arquitectura **ETL (Extract, Transform, Load)** serverless para desacoplar el analytics del servidor web de producci√≥n.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Supabase DB    ‚îÇ
‚îÇ  (Raw Logs)     ‚îÇ
‚îÇ  access_logs    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Extract (Python Client)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Python Script  ‚îÇ
‚îÇ  ETL Process    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Transform (Polars)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Data Processing ‚îÇ
‚îÇ - Clean         ‚îÇ
‚îÇ - Aggregate     ‚îÇ
‚îÇ - Categorize    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Key Metrics    ‚îÇ ‚îÄ‚îÄ‚îÄ> ‚îÇ  HTML Report     ‚îÇ
‚îÇ  - Attack Stats ‚îÇ      ‚îÇ  (Jinja2 Render) ‚îÇ
‚îÇ  - Geo Analysis ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  - Performance  ‚îÇ               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ Dispatch
                                  ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  Resend API      ‚îÇ
                         ‚îÇ  Email Delivery  ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GitHub Actions (Cron: Monthly)         ‚îÇ
‚îÇ  Orchestrates entire pipeline           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tech Stack

| Componente | Tecnolog√≠a |
|------------|------------|
| **Source** | Supabase (PostgreSQL) |
| **Processing** | Python 3.10 + Polars |
| **Orchestration** | GitHub Actions (CI/CD Cron) |
| **Delivery** | Resend API (Email) |
| **Templating** | Jinja2 |

---

## üöÄ Caracter√≠sticas Clave y Detalles de Implementaci√≥n

### 1. Extracci√≥n de Datos (Integraci√≥n API)

En lugar de consultar continuamente la base de datos de producci√≥n, el script realiza una extracci√≥n por lotes de los datos del mes anterior usando el cliente Python de Supabase, asegurando un impacto m√≠nimo en el rendimiento web.

```python
response = self.supabase.table("access_logs") \
    .select("*") \
    .gte("timestamp", start_date.isoformat()) \
    .lt("timestamp", end_date.isoformat()) \
    .execute()
```

### 2. Transformaci√≥n de Datos (Polars)

Los logs crudos son desordenados. El pipeline realiza varios pasos de limpieza:

- **Conversi√≥n de Tipos**: Convertir strings ISO 8601 a objetos Python Datetime
- **Categorizaci√≥n**: L√≥gica para clasificar tr√°fico en buckets `Leg√≠timo`, `Bots` y `Malicioso` bas√°ndose en c√≥digos de acci√≥n del middleware
- **Agregaci√≥n**: Agrupar ataques por c√≥digos de pa√≠s ISO y calcular distribuciones de frecuencia para IPs sospechosas

### 3. Inteligencia de Negocio (El Reporte)

El output no es solo un CSV. Es un dashboard HTML renderizado que responde preguntas de negocio:

- **Postura de Seguridad**: % de ataques bloqueados vs. tr√°fico total
- **An√°lisis Geo-Espacial**: Top 5 pa√≠ses atacando la infraestructura
- **Rendimiento**: Seguimiento de latencia promedio para asegurar que la capa de seguridad no est√© ralentizando la UX

---

## Configuraci√≥n y Uso

### Prerrequisitos

- Python 3.9+
- Un proyecto Supabase con una tabla `access_logs`
- Una API Key de Resend.com

### Instalaci√≥n

1. Clonar el repositorio:

```bash
git clone https://github.com/tommcrojo/middleware-analytics.git
cd middleware-analytics
```

2. Instalar dependencias:

```bash
pip install -r requirements.txt
```

3. Configurar Variables de Entorno (`.env`):

```bash
SUPABASE_URL="your-project-url"
SUPABASE_KEY="your-service-role-key"
RESEND_API_KEY="your-resend-key"
ADMIN_EMAIL="admin@company.com"
```

### Ejecutar el Pipeline

```bash
python src/main.py
```

### Demo con Datos Mock

Si no tienes credenciales de Supabase, puedes usar los datos de ejemplo:

```bash
python src/main.py --use-mock-data
```

---

## Estructura del Proyecto

```
middleware-analytics/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                 # Script ETL principal
‚îú‚îÄ‚îÄ benchmarks/
‚îÇ   ‚îî‚îÄ‚îÄ compare_polars_pandas.py # Script benchmark de desempe√±o
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ mock_logs.csv          # 50k registros mock para benchmarks/demos
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ sample_report.png      # Captura del reporte HTML
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ monthly_report.yml # Automatizaci√≥n CI/CD
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ README.md
```

---

## Automatizaci√≥n con GitHub Actions

El pipeline se ejecuta autom√°ticamente el d√≠a 1 de cada mes a las 9:00 AM UTC:

```yaml
on:
  schedule:
    - cron: '0 9 1 * *'
  workflow_dispatch:  # Tambi√©n permite ejecuci√≥n manual
```

Las credenciales se gestionan de forma segura usando GitHub Secrets.

---

## Habilidades Demostradas

- **Ingenier√≠a de Datos**: Dise√±o de un proceso ETL robusto desde cero
- **Ecosistema Python**: Uso avanzado de Polars para manipulaci√≥n de datos de alto rendimiento
- **Automatizaci√≥n Cloud**: Utilizaci√≥n de GitHub Actions para scheduling basado en cron
- **SQL y Bases de Datos**: Interacci√≥n con APIs basadas en PostgreSQL
- **Comunicaci√≥n de Negocio**: Traducir logs t√©cnicos crudos a insights de nivel ejecutivo

---

## M√©tricas Clave Generadas

El reporte incluye:

1. **Resumen Ejecutivo**
   - Total de peticiones procesadas
   - Amenazas bloqueadas
   - Score de seguridad (%)
   - Latencia promedio del middleware

2. **An√°lisis Geogr√°fico**
   - Top 5 pa√≠ses origen de ataques
   - Distribuci√≥n de tr√°fico leg√≠timo vs malicioso

3. **Inteligencia de Amenazas**
   - IPs de alto riesgo (>5 intentos bloqueados)
   - Patrones de ataque recurrentes

4. **Calidad del Tr√°fico**
   - Ratio de bots vs usuarios reales
   - Efectividad del filtrado

---

## Consideraciones de Seguridad

- Las credenciales nunca se commitean al repositorio (uso de `.env` y GitHub Secrets)
- El script usa `service_role_key` de Supabase con permisos de solo lectura
- Los datos sensibles (IPs reales) se pueden anonimizar antes del env√≠o del reporte

---

## Mejoras Futuras

- **Alertas en Tiempo Real**: Integraci√≥n con Slack/PagerDuty para ataques en curso
- **Dashboard Interactivo**: Panel web con Streamlit o Metabase
- **Machine Learning**: Detecci√≥n de anomal√≠as usando modelos de clustering
- **Almacenamiento Hist√≥rico**: Data warehouse para an√°lisis de tendencias a largo plazo

---

## Licencia

Este proyecto est√° licenciado bajo la licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

---

## Autor

**Tom√°s Campoy Rojo**
- GitHub: [@tommcrojo](https://github.com/tommcrojo)

---

## Agradecimientos

Este proyecto fue desarrollado como parte de una consultor√≠a real para optimizar la visibilidad de seguridad de infraestructura web empresarial.
